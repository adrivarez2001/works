{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5600bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# CSV\n",
    "import csv\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import sklearn\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, make_scorer\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "#Import the SMOTE-NC\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b39f27",
   "metadata": {},
   "source": [
    "### Read from telco_churn_cleaned.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "963844dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = pd.read_csv('telco_churn_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7181c4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>...</th>\n",
       "      <th>internet_service_dsl</th>\n",
       "      <th>internet_service_fiber_optic</th>\n",
       "      <th>internet_service_no</th>\n",
       "      <th>contract_month_to_month</th>\n",
       "      <th>contract_one_year</th>\n",
       "      <th>contract_two_year</th>\n",
       "      <th>payment_method_bank_transfer</th>\n",
       "      <th>payment_method_credit_card</th>\n",
       "      <th>payment_method_electronic_check</th>\n",
       "      <th>payment_method_mailed_check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.152778</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7042</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7043 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SeniorCitizen  Partner  Dependents    tenure  MultipleLines  \\\n",
       "0                 0        1           0  0.013889              0   \n",
       "1                 0        0           0  0.472222              0   \n",
       "2                 0        0           0  0.027778              0   \n",
       "3                 0        0           0  0.625000              0   \n",
       "4                 0        0           0  0.027778              0   \n",
       "...             ...      ...         ...       ...            ...   \n",
       "7038              0        1           1  0.333333              1   \n",
       "7039              0        1           1  1.000000              1   \n",
       "7040              0        1           1  0.152778              0   \n",
       "7041              1        1           0  0.055556              1   \n",
       "7042              0        0           0  0.916667              0   \n",
       "\n",
       "      OnlineSecurity  OnlineBackup  DeviceProtection  TechSupport  \\\n",
       "0                  0             1                 0            0   \n",
       "1                  1             0                 1            0   \n",
       "2                  1             1                 0            0   \n",
       "3                  1             0                 1            1   \n",
       "4                  0             0                 0            0   \n",
       "...              ...           ...               ...          ...   \n",
       "7038               1             0                 1            1   \n",
       "7039               0             1                 1            0   \n",
       "7040               1             0                 0            0   \n",
       "7041               0             0                 0            0   \n",
       "7042               1             0                 1            1   \n",
       "\n",
       "      StreamingTV  ...  internet_service_dsl  internet_service_fiber_optic  \\\n",
       "0               0  ...                     1                             0   \n",
       "1               0  ...                     1                             0   \n",
       "2               0  ...                     1                             0   \n",
       "3               0  ...                     1                             0   \n",
       "4               0  ...                     0                             1   \n",
       "...           ...  ...                   ...                           ...   \n",
       "7038            1  ...                     1                             0   \n",
       "7039            1  ...                     0                             1   \n",
       "7040            0  ...                     1                             0   \n",
       "7041            0  ...                     0                             1   \n",
       "7042            1  ...                     0                             1   \n",
       "\n",
       "      internet_service_no  contract_month_to_month  contract_one_year  \\\n",
       "0                       0                        1                  0   \n",
       "1                       0                        0                  1   \n",
       "2                       0                        1                  0   \n",
       "3                       0                        0                  1   \n",
       "4                       0                        1                  0   \n",
       "...                   ...                      ...                ...   \n",
       "7038                    0                        0                  1   \n",
       "7039                    0                        0                  1   \n",
       "7040                    0                        1                  0   \n",
       "7041                    0                        1                  0   \n",
       "7042                    0                        0                  0   \n",
       "\n",
       "      contract_two_year  payment_method_bank_transfer  \\\n",
       "0                     0                             0   \n",
       "1                     0                             0   \n",
       "2                     0                             0   \n",
       "3                     0                             1   \n",
       "4                     0                             0   \n",
       "...                 ...                           ...   \n",
       "7038                  0                             0   \n",
       "7039                  0                             0   \n",
       "7040                  0                             0   \n",
       "7041                  0                             0   \n",
       "7042                  1                             1   \n",
       "\n",
       "      payment_method_credit_card  payment_method_electronic_check  \\\n",
       "0                              0                                1   \n",
       "1                              0                                0   \n",
       "2                              0                                0   \n",
       "3                              0                                0   \n",
       "4                              0                                1   \n",
       "...                          ...                              ...   \n",
       "7038                           0                                0   \n",
       "7039                           1                                0   \n",
       "7040                           0                                1   \n",
       "7041                           0                                0   \n",
       "7042                           0                                0   \n",
       "\n",
       "      payment_method_mailed_check  \n",
       "0                               0  \n",
       "1                               1  \n",
       "2                               1  \n",
       "3                               0  \n",
       "4                               0  \n",
       "...                           ...  \n",
       "7038                            1  \n",
       "7039                            0  \n",
       "7040                            0  \n",
       "7041                            1  \n",
       "7042                            0  \n",
       "\n",
       "[7043 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7968ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = customer_df.drop(columns={'Churn'})\n",
    "y = customer_df['Churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9d90e8",
   "metadata": {},
   "source": [
    "## SMOTE-NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94472dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the oversampler. For SMOTE-NC we need to pinpoint the column position where is the categorical features are. In this case, 'IsActiveMember' is positioned in the second column we input [1] as the parameter. If you have more than one categorical columns, just input all the columns position\n",
    "smotenc = SMOTENC([0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],random_state = 424)\n",
    "X, y = smotenc.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88a4919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 424)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf3f5c7",
   "metadata": {},
   "source": [
    "## Decision Tree Base Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "996b844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier()  \n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "dt_predictions = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5776f73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "854\n",
      "227\n",
      "774\n",
      "215\n"
     ]
    }
   ],
   "source": [
    "dt_conf_matrix = confusion_matrix(y_test, dt_predictions)\n",
    "dt_tn = dt_conf_matrix[0][0]\n",
    "dt_fn = dt_conf_matrix[1][0]\n",
    "dt_tp = dt_conf_matrix[1][1]\n",
    "dt_fp = dt_conf_matrix[0][1]\n",
    "print(dt_tn)\n",
    "print(dt_fn)\n",
    "print(dt_tp)\n",
    "print(dt_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab89ca2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy Score: 0.7864734299516908\n",
      "Decision Tree Precision Score: 0.782608695652174\n",
      "Decision Tree Recall Score: 0.7732267732267732\n",
      "Decision Tree F1-Score: 0.7778894472361809\n",
      "RMSE for KNN: 0.4620893528835188\n"
     ]
    }
   ],
   "source": [
    "dt_accuracy = (dt_tp + dt_tn) / (dt_tp + dt_tn + dt_fp + dt_fn)\n",
    "dt_precision = dt_tp / (dt_tp + dt_fp)\n",
    "dt_recall = dt_tp / (dt_tp + dt_fn)\n",
    "dt_f1_score = 2 * ((dt_precision * dt_recall) / (dt_precision + dt_recall))\n",
    "\n",
    "print('Decision Tree Accuracy Score: ' + str(dt_accuracy))\n",
    "print('Decision Tree Precision Score: ' + str(dt_precision))\n",
    "print('Decision Tree Recall Score: ' + str(dt_recall))\n",
    "print('Decision Tree F1-Score: ' + str(dt_f1_score))\n",
    "print(f\"RMSE for KNN: {math.sqrt(mean_squared_error(y_test,dt_predictions))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d1a368",
   "metadata": {},
   "source": [
    "## Decision Tree after Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1133ebf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[824 245]\n",
      " [194 807]]\n",
      "Accuracy: 0.7879227053140097\n",
      "Precision: 0.7671102661596958\n",
      "Recall: 0.8061938061938062\n",
      "F1: 0.7861665854846566\n",
      "RMSE: 0.46051850634474\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=10)  \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix of the result\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Find the accuracy and F1 score of the result\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "# Find the accuracy and F1 score of the result\n",
    "print('Accuracy: ' + str(accuracy))\n",
    "print('Precision: ' + str(precision))\n",
    "print('Recall: ' + str(recall))\n",
    "print('F1: ' + str(f1))\n",
    "print('RMSE: ' + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d64df",
   "metadata": {},
   "source": [
    "## Decision Tree w/ AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c57e6e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[905 164]\n",
      " [165 836]]\n",
      "Accuracy: 0.8410628019323672\n",
      "Precision: 0.836\n",
      "Recall: 0.8351648351648352\n",
      "F1: 0.8355822088955521\n",
      "RMSE: 0.39866928407846125\n"
     ]
    }
   ],
   "source": [
    "# - n_estimator is the number of base classifiers (i.e. weak learners)\n",
    "# - learning_rate controls the weight adjustments of each base classifiers. \n",
    "model = AdaBoostClassifier(n_estimators=400,learning_rate=0.1,base_estimator=dt_clf, random_state=424)\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix of the result\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Find the accuracy, precision, recall and F1 score of the result\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "print('Accuracy: ' + str(accuracy))\n",
    "print('Precision: ' + str(precision))\n",
    "print('Recall: ' + str(recall))\n",
    "print('F1: ' + str(f1))\n",
    "print('RMSE: ' + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232e3e2e",
   "metadata": {},
   "source": [
    "## Decision Tree w/ Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3797bf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[880 189]\n",
      " [147 854]]\n",
      "Accuracy: 0.8376811594202899\n",
      "Precision: 0.8187919463087249\n",
      "Recall: 0.8531468531468531\n",
      "F1: 0.8356164383561643\n",
      "RMSE: 0.4028881241482679\n"
     ]
    }
   ],
   "source": [
    "# Create the Bagging classifier. Default base classifiers is Decision Tree. \n",
    "# - n_estimator is the number of base classifiers (i.e. weak learners)\n",
    "model = BaggingClassifier(n_estimators=500, base_estimator=dt_clf)\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix of the result\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Find the accuracy, precision, recall and F1 score of the resultaccuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "# Find the accuracy and F1 score of the result\n",
    "print('Accuracy: ' + str(accuracy))\n",
    "print('Precision: ' + str(precision))\n",
    "print('Recall: ' + str(recall))\n",
    "print('F1: ' + str(f1))\n",
    "print('RMSE: ' + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23faa4c6",
   "metadata": {},
   "source": [
    "## Random Forest Base Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a646a34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[896 173]\n",
      " [138 863]]\n",
      "Accuracy: 0.8497584541062801\n",
      "Precision: 0.833011583011583\n",
      "Recall: 0.8621378621378621\n",
      "F1: 0.8473244968090328\n",
      "RMSE: 0.3876100435924227\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix of the result\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Find the accuracy and F1 score of the result\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "# Find the accuracy and F1 score of the result\n",
    "print('Accuracy: ' + str(accuracy))\n",
    "print('Precision: ' + str(precision))\n",
    "print('Recall: ' + str(recall))\n",
    "print('F1: ' + str(f1))\n",
    "print('RMSE: ' + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ef66c",
   "metadata": {},
   "source": [
    "## Random Forest after Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a0188b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=500, random_state=424)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=500, random_state=424)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, random_state=424)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, random_state=424)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9608ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fb25cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_conf_matrix = confusion_matrix(y_test, rfc_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49bbee57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[906, 163],\n",
       "       [135, 866]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dedf4add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866\n",
      "906\n",
      "163\n",
      "135\n"
     ]
    }
   ],
   "source": [
    "rfc_tn = rfc_conf_matrix[0][0]\n",
    "rfc_fn = rfc_conf_matrix[1][0]\n",
    "rfc_tp = rfc_conf_matrix[1][1]\n",
    "rfc_fp = rfc_conf_matrix[0][1]\n",
    "print(rfc_tp)\n",
    "print(rfc_tn)\n",
    "print(rfc_fp)\n",
    "print(rfc_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b57310c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy Score: 0.8560386473429952\n",
      "Random Forest Precision Score: 0.8415937803692906\n",
      "Random Forest Recall Score: 0.8651348651348651\n",
      "Random Forest F1-Score: 0.8532019704433498\n"
     ]
    }
   ],
   "source": [
    "rfc_accuracy = (rfc_tp + rfc_tn) / (rfc_tp + rfc_tn + rfc_fp + rfc_fn)\n",
    "rfc_precision = rfc_tp / (rfc_tp + rfc_fp)\n",
    "rfc_recall = rfc_tp / (rfc_tp + rfc_fn)\n",
    "rfc_f1_score = 2 * ((rfc_precision * rfc_recall) / (rfc_precision + rfc_recall))\n",
    "\n",
    "print('Random Forest Accuracy Score: ' + str(rfc_accuracy))\n",
    "print('Random Forest Precision Score: ' + str(rfc_precision))\n",
    "print('Random Forest Recall Score: ' + str(rfc_recall))\n",
    "print('Random Forest F1-Score: ' + str(rfc_f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7183688",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c4f15a",
   "metadata": {},
   "source": [
    "## Naive Bayes Base Classifier \n",
    "\n",
    "Note: NB no hyperparameters tuning because no applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac5f8675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[788 281]\n",
      " [178 823]]\n",
      "Accuracy for Naive Bayes: 0.7782608695652173\n",
      "Precision for Naive Bayes: 0.7454710144927537\n",
      "Recall for Naive Bayes: 0.8221778221778222\n",
      "F1-Score for Naive Bayes: 0.7819477434679335\n"
     ]
    }
   ],
   "source": [
    "#Initialize or define the model\n",
    "nb = GaussianNB()\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "predictions_nb= nb.predict(X_test)\n",
    "\n",
    "#Find the confusion matrix of the result\n",
    "cm = confusion_matrix(y_test, predictions_nb)\n",
    "print(cm)\n",
    "\n",
    "#Print the accuracy, precision, recall, and F1 score of the result\n",
    "print(f\"Accuracy for Naive Bayes: {accuracy_score(y_test, predictions_nb)}\")\n",
    "print(f\"Precision for Naive Bayes: {precision_score(y_test, predictions_nb)}\")\n",
    "print(f\"Recall for Naive Bayes: {recall_score(y_test, predictions_nb)}\")\n",
    "print(f\"F1-Score for Naive Bayes: {f1_score(y_test, predictions_nb)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd640a77",
   "metadata": {},
   "source": [
    "## Naive Bayes after Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbabc62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[787 282]\n",
      " [178 823]]\n",
      "Accuracy: 0.7777777777777778\n",
      "Precision: 0.7447963800904978\n",
      "Recall: 0.8221778221778222\n",
      "F1: 0.7815764482431149\n",
      "RMSE: 0.4714045207910317\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB(var_smoothing=0.008111308307896872)  \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix of the result\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Find the accuracy and F1 score of the result\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "# Find the accuracy and F1 score of the result\n",
    "print('Accuracy: ' + str(accuracy))\n",
    "print('Precision: ' + str(precision))\n",
    "print('Recall: ' + str(recall))\n",
    "print('F1: ' + str(f1))\n",
    "print('RMSE: ' + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba0f529",
   "metadata": {},
   "source": [
    "## Naive Bayes w/ AdaBoost (Not recommended to use AdaBoost here)\n",
    "\n",
    "https://www.researchgate.net/publication/220541785_A_Study_of_AdaBoost_with_Naive_Bayesian_Classifiers_Weakness_and_Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "455f0233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[825 244]\n",
      " [182 819]]\n",
      "Accuracy: 0.7942028985507247\n",
      "Precision: 0.7704609595484478\n",
      "Recall: 0.8181818181818182\n",
      "F1: 0.7936046511627907\n",
      "RMSE: 0.4536486541909668\n"
     ]
    }
   ],
   "source": [
    "# - n_estimator is the number of base classifiers (i.e. weak learners)\n",
    "# - learning_rate controls the weight adjustments of each base classifiers. Default is 1\n",
    "model = AdaBoostClassifier(n_estimators=400,learning_rate=0.1,base_estimator=nb, random_state=424)\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix of the result\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Find the accuracy and F1 score of the result\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "# Note: Precision and Recall are missing here, you could add them for the baseline\n",
    "\n",
    "print('Accuracy: ' + str(accuracy))\n",
    "print('Precision: ' + str(precision))\n",
    "print('Recall: ' + str(recall))\n",
    "print('F1: ' + str(f1))\n",
    "print('RMSE: ' + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f21fddd",
   "metadata": {},
   "source": [
    "## Naive Bayes w/ Bagging (No effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "288964ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[788 281]\n",
      " [178 823]]\n",
      "Accuracy: 0.7782608695652173\n",
      "Precision: 0.7454710144927537\n",
      "Recall: 0.8221778221778222\n",
      "F1: 0.7819477434679335\n",
      "RMSE0.47089184579347154\n"
     ]
    }
   ],
   "source": [
    "#For Bagging implementation\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#Create the Bagging classifier. Default base classifiers is Decision Tree. \n",
    "# - n_estimator is the number of base classifiers (i.e. weak learners)\n",
    "model = BaggingClassifier(n_estimators=100, base_estimator=nb)\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix of the result\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Find the accuracy and F1 score of the result\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "# Find the accuracy and F1 score of the result\n",
    "print('Accuracy: ' + str(accuracy))\n",
    "print('Precision: ' + str(precision))\n",
    "print('Recall: ' + str(recall))\n",
    "print('F1: ' + str(f1))\n",
    "print('RMSE' + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5935a2",
   "metadata": {},
   "source": [
    "## Logistic Regression Base Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2154a5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Logistic Regression: [[821 248]\n",
      " [175 826]]\n",
      "Accuracy for Logistic Regression: 0.7956521739130434\n",
      "Precision for Logistic Regression: 0.7690875232774674\n",
      "Recall for Logistic Regression: 0.8251748251748252\n",
      "F1-Score for Logistic Regression: 0.7961445783132531\n",
      "RMSE: 0.4520484775850446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jon/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "predictions_logreg = logreg.predict(X_test)\n",
    "cm_logreg = confusion_matrix(y_test, predictions_logreg)\n",
    "rmse = math.sqrt(mean_squared_error(y_test,predictions_logreg))\n",
    "\n",
    "#Print the accuracy, precision, recall, and F1 score of the result\n",
    "print(f\"Confusion Matrix for Logistic Regression: {cm_logreg}\")\n",
    "print(f\"Accuracy for Logistic Regression: {accuracy_score(y_test, predictions_logreg)}\")\n",
    "print(f\"Precision for Logistic Regression: {precision_score(y_test, predictions_logreg)}\")\n",
    "print(f\"Recall for Logistic Regression: {recall_score(y_test, predictions_logreg)}\")\n",
    "print(f\"F1-Score for Logistic Regression: {f1_score(y_test, predictions_logreg)}\")\n",
    "print('RMSE: ' + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a94f5f7",
   "metadata": {},
   "source": [
    "## Logistic Regression after Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73456ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Logistic Regression: 0.7951690821256039\n",
      "Precision for Logistic Regression: 0.7649219467401286\n",
      "Recall for Logistic Regression: 0.8321678321678322\n",
      "F1-Score for Logistic Regression: 0.7971291866028708\n",
      "RMSE: 0.47089184579347154\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='lbfgs', penalty='none', random_state=424, max_iter=100)\n",
    "logreg.fit(X_train, y_train)\n",
    "predictions_logreg = logreg.predict(X_test)\n",
    "cm_logreg = confusion_matrix(y_test, predictions_logreg)\n",
    "rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "#Print the accuracy, precision, recall, and F1 score of the result\n",
    "print(f\"Accuracy for Logistic Regression: {accuracy_score(y_test, predictions_logreg)}\")\n",
    "print(f\"Precision for Logistic Regression: {precision_score(y_test, predictions_logreg)}\")\n",
    "print(f\"Recall for Logistic Regression: {recall_score(y_test, predictions_logreg)}\")\n",
    "print(f\"F1-Score for Logistic Regression: {f1_score(y_test, predictions_logreg)}\")\n",
    "print('RMSE: ' + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153243c2",
   "metadata": {},
   "source": [
    "## Logistic Regression w/ AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad523991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[815 254]\n",
      " [171 830]]\n",
      "AdaBoost w/ LR Accuracy: 0.7946859903381642\n",
      "AdaBoost w/ LR Precision: 0.7656826568265682\n",
      "AdaBoost w/ LR Recall: 0.8291708291708292\n",
      "AdaBoost w/ LR F1: 0.7961630695443644\n",
      "RMSE: 0.45311588988010093\n"
     ]
    }
   ],
   "source": [
    "# Follow the baseline's setup\n",
    "#For AdaBoost implementation\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#Create the AdaBoost classifier\n",
    "# - n_estimator is the number of base classifiers (i.e. weak learners)\n",
    "# - learning_rate controls the weight adjustments of each base classifiers. Default is 1\n",
    "model = AdaBoostClassifier(n_estimators=100,learning_rate=0.1,base_estimator=logreg)\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix of the result\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Find the accuracy and F1 score of the result\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "\n",
    "# Note: Precision and Recall are missing here, you could add them for the baseline\n",
    "\n",
    "print('AdaBoost w/ LR Accuracy: ' + str(accuracy))\n",
    "print('AdaBoost w/ LR Precision: ' + str(precision))\n",
    "print('AdaBoost w/ LR Recall: ' + str(recall))\n",
    "\n",
    "print('AdaBoost w/ LR F1: ' + str(f1))\n",
    "print('RMSE: ' + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765c6838",
   "metadata": {},
   "source": [
    "## Logistic Regression w/ Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23a0032c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[814 255]\n",
      " [167 834]]\n",
      "Accuracy for Logistic Regression: 0.7961352657004831\n",
      "Precision for Logistic Regression: 0.7658402203856749\n",
      "Recall for Logistic Regression: 0.8331668331668332\n",
      "F1-Score for Logistic Regression: 0.7980861244019138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#For Bagging implementation\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#Create the Bagging classifier. Default base classifiers is Decision Tree. \n",
    "# - n_estimator is the number of base classifiers (i.e. weak learners)\n",
    "model = BaggingClassifier(n_estimators=100, base_estimator=logreg)\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix of the result\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Find the accuracy and F1 score of the result\n",
    "print(f\"Accuracy for Logistic Regression: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Precision for Logistic Regression: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Recall for Logistic Regression: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"F1-Score for Logistic Regression: {f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6131fa3",
   "metadata": {},
   "source": [
    "## SVM Base Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7dd71131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[813 256]\n",
      " [168 833]]\n",
      "linearSVC Accuracy: 0.7951690821256039\n",
      "linearSVC Precision: 0.7649219467401286\n",
      "linearSVC Recall: 0.8321678321678322\n",
      "linearSVC F1: 0.7971291866028708\n",
      "Time taken:\n",
      "0:00:00.167524\n"
     ]
    }
   ],
   "source": [
    "start=datetime.now()\n",
    "\n",
    "#Initialize or define the model\n",
    "linearSVC_svm = LinearSVC()\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "linearSVC_svm.fit(X_train, y_train)\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "linearSVC_svm_pred = linearSVC_svm.predict(X_test)\n",
    "\n",
    "#Find the confusion matrix of the result\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, linearSVC_svm_pred))\n",
    "\n",
    "linearSVC_svm_accuracy = accuracy_score(y_test, linearSVC_svm_pred)\n",
    "print('linearSVC Accuracy: ' + str(linearSVC_svm_accuracy))\n",
    "\n",
    "linearSVC_svm_precision = precision_score(y_test, linearSVC_svm_pred)\n",
    "print('linearSVC Precision: ' + str(linearSVC_svm_precision))\n",
    "\n",
    "linearSVC_svm_recall = recall_score(y_test, linearSVC_svm_pred)\n",
    "print('linearSVC Recall: ' + str(linearSVC_svm_recall))\n",
    "\n",
    "linearSVC_svm_f1 = f1_score(y_test, linearSVC_svm_pred)\n",
    "print('linearSVC F1: ' + str(linearSVC_svm_f1))\n",
    "\n",
    "print('Time taken:')\n",
    "print(datetime.now()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6740d6",
   "metadata": {},
   "source": [
    "## SVM after Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41375e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[812 257]\n",
      " [167 834]]\n",
      "linearSVC Accuracy: 0.7951690821256039\n",
      "linearSVC Precision: 0.7644362969752521\n",
      "linearSVC Recall: 0.8331668331668332\n",
      "linearSVC F1: 0.7973231357552581\n",
      "Time taken:\n",
      "0:00:00.109408\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "#from sklearn.svm import SVC \n",
    "\n",
    "#Your code here. The following comments are just for your reference\n",
    "\n",
    "#ADDED MYSELF\n",
    "start=datetime.now()\n",
    "#END\n",
    "\n",
    "#Initialize or define the model\n",
    "linearSVC_svm = LinearSVC(C=0.5, max_iter=1000)\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "linearSVC_svm.fit(X_train, y_train)\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "linearSVC_svm_pred = linearSVC_svm.predict(X_test)\n",
    "\n",
    "#Find the confusion matrix of the result\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, linearSVC_svm_pred))\n",
    "\n",
    "#Print the accuracy, precision, recall, and F1 score of the result\n",
    "# print('Accuracy:')\n",
    "# print(linearSVC_svm.score(X_test, y_test))\n",
    "linearSVC_svm_accuracy = accuracy_score(y_test, linearSVC_svm_pred)\n",
    "print('linearSVC Accuracy: ' + str(linearSVC_svm_accuracy))\n",
    "\n",
    "linearSVC_svm_precision = precision_score(y_test, linearSVC_svm_pred)\n",
    "print('linearSVC Precision: ' + str(linearSVC_svm_precision))\n",
    "\n",
    "linearSVC_svm_recall = recall_score(y_test, linearSVC_svm_pred)\n",
    "print('linearSVC Recall: ' + str(linearSVC_svm_recall))\n",
    "\n",
    "linearSVC_svm_f1 = f1_score(y_test, linearSVC_svm_pred)\n",
    "print('linearSVC F1: ' + str(linearSVC_svm_f1))\n",
    "\n",
    "print('Time taken:')\n",
    "print(datetime.now()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20be53f",
   "metadata": {},
   "source": [
    "### SVM w/ AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31682ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[832 237]\n",
      " [199 802]]\n",
      "ada_LinearSVC_SVM accuracy: 0.7893719806763285\n",
      "ada_LinearSVC_SVM precision: 0.7718960538979788\n",
      "ada_LinearSVC_SVM recall: 0.8011988011988012\n",
      "ada_LinearSVC_SVM f1: 0.7862745098039217\n",
      "Time taken:\n",
      "0:00:00\n"
     ]
    }
   ],
   "source": [
    "# Follow the baseline's setup\n",
    "\n",
    "#Create the AdaBoost classifier\n",
    "# - n_estimator is the number of base classifiers (i.e. weak learners)\n",
    "# - learning_rate controls the weight adjustments of each base classifiers. Default is 1\n",
    "ada_linearSVC_svm_model = AdaBoostClassifier(n_estimators=100,learning_rate=0.1,base_estimator=linearSVC_svm, algorithm='SAMME')\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "ada_linearSVC_svm_model.fit(X_train, y_train)\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "ada_linearSVC_svm_ypred = ada_linearSVC_svm_model.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix of the result\n",
    "ada_linearSVC_svm_cm = confusion_matrix(y_test, ada_linearSVC_svm_ypred)\n",
    "print(ada_linearSVC_svm_cm)\n",
    "\n",
    "# Find the accuracy and F1 score of the result\n",
    "ada_linearSVC_svm_accuracy = accuracy_score(y_test, ada_linearSVC_svm_ypred)\n",
    "ada_linearSVC_svm_precision = precision_score(y_test, ada_linearSVC_svm_ypred)\n",
    "ada_linearSVC_svm_recall = recall_score(y_test, ada_linearSVC_svm_ypred)\n",
    "\n",
    "ada_linearSVC_svm_f1 = f1_score(y_test, ada_linearSVC_svm_ypred)\n",
    "\n",
    "# Note: Precision and Recall are missing here, you could add them for the baseline\n",
    "\n",
    "print('ada_LinearSVC_SVM accuracy: ' + str(ada_linearSVC_svm_accuracy))\n",
    "print('ada_LinearSVC_SVM precision: ' + str(ada_linearSVC_svm_precision))\n",
    "print('ada_LinearSVC_SVM recall: ' + str(ada_linearSVC_svm_recall))\n",
    "\n",
    "print('ada_LinearSVC_SVM f1: ' + str(ada_linearSVC_svm_f1))\n",
    "\n",
    "start=datetime.now()\n",
    "print('Time taken:')\n",
    "print(datetime.now()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb7790b",
   "metadata": {},
   "source": [
    "## SVM w/ Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "293ee88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Samuel Thong\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[812 257]\n",
      " [167 834]]\n",
      "Accuracy: 0.7951690821256039\n",
      "Precision: 0.7644362969752521\n",
      "Recall: 0.8331668331668332\n",
      "F1-Score: 0.7973231357552581\n"
     ]
    }
   ],
   "source": [
    "#For Bagging implementation\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#Create the Bagging classifier. Default base classifiers is Decision Tree. \n",
    "# - n_estimator is the number of base classifiers (i.e. weak learners)\n",
    "model = BaggingClassifier(n_estimators=200, base_estimator=linearSVC_svm)\n",
    "\n",
    "#Fit the training feature Xs and training label Ys\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Use the trained model to predict the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Find the confusion matrix of the result\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Find the accuracy and F1 score of the result\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0c2d11",
   "metadata": {},
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc665459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for LGBM:  91.24%\n",
      "Accuracy Score for LGBM :  0.836231884057971\n",
      "Precision Score for LGBM :  0.8134469696969697\n",
      "Recall Score for LGBM :  0.8581418581418582\n",
      "F1-Score Score for LGBM :  0.8351968886728245\n",
      "RMSE Score for LGBM :  0.40468273491962686\n"
     ]
    }
   ],
   "source": [
    "classifier_lgbm = LGBMClassifier()\n",
    "\n",
    "# Defining the Classification Model\n",
    "def model(classifier,X_train,y_train,X_test,y_test):\n",
    "    \n",
    "    classifier.fit(X_train,y_train)\n",
    "    prediction = classifier.predict(X_test)\n",
    "    cv = RepeatedStratifiedKFold(n_splits = 10,n_repeats = 3,random_state = 1)\n",
    "    print(\"Cross Validation Score for LGBM: \",'{0:.2%}'.format(cross_val_score(classifier,X_train,y_train,cv = cv,scoring = 'roc_auc').mean()))\n",
    "    print(\"Accuracy Score for LGBM : \", accuracy_score(y_test, prediction))\n",
    "    print(\"Precision Score for LGBM : \", precision_score(y_test, prediction))\n",
    "    print(\"Recall Score for LGBM : \", recall_score(y_test, prediction))\n",
    "    print(\"F1-Score Score for LGBM : \", f1_score(y_test, prediction))\n",
    "    print(\"RMSE Score for LGBM : \", math.sqrt(mean_squared_error(y_test,prediction)))\n",
    "\n",
    "    \n",
    "model(classifier_lgbm,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e2a130",
   "metadata": {},
   "source": [
    "# Light GBM with Hyper Parameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dbb5f5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for LGBM:  91.31%\n",
      "Accuracy Score for LGBM :  0.8415458937198068\n",
      "Precision Score for LGBM :  0.8232468780019212\n",
      "Recall Score for LGBM :  0.8561438561438561\n",
      "F1-Score Score for LGBM :  0.8393731635651323\n",
      "RMSE Score for LGBM :  0.3980629426110816\n"
     ]
    }
   ],
   "source": [
    "classifier_lgbm = LGBMClassifier(\n",
    "    reg_alpha= 0,\n",
    "    reg_lambda= 0,\n",
    "    colsample_bytree= 0.6,\n",
    "    subsample= 0.8,\n",
    "    learning_rate= 0.02,\n",
    "    max_depth= 20,\n",
    "    num_leaves= 300,\n",
    "    min_child_samples= 10)\n",
    "\n",
    "# Defining the Classification Model\n",
    "def model(classifier,X_train,y_train,X_test,y_test):\n",
    "    \n",
    "    classifier.fit(X_train,y_train)\n",
    "    prediction = classifier.predict(X_test)\n",
    "    cv = RepeatedStratifiedKFold(n_splits = 10,n_repeats = 3,random_state = 1)\n",
    "    print(\"Cross Validation Score for LGBM: \",'{0:.2%}'.format(cross_val_score(classifier,X_train,y_train,cv = cv,scoring = 'roc_auc').mean()))\n",
    "    print(\"Accuracy Score for LGBM : \", accuracy_score(y_test, prediction))\n",
    "    print(\"Precision Score for LGBM : \", precision_score(y_test, prediction))\n",
    "    print(\"Recall Score for LGBM : \", recall_score(y_test, prediction))\n",
    "    print(\"F1-Score Score for LGBM : \", f1_score(y_test, prediction))\n",
    "    print(\"RMSE Score for LGBM : \", math.sqrt(mean_squared_error(y_test,prediction)))\n",
    "\n",
    "    \n",
    "model(classifier_lgbm,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d86d37",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e2a383a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "259/259 - 1s - loss: 0.6205 - accuracy: 0.7155 - val_loss: 0.4743 - val_accuracy: 0.7831 - 887ms/epoch - 3ms/step\n",
      "Epoch 2/200\n",
      "259/259 - 0s - loss: 0.4713 - accuracy: 0.7770 - val_loss: 0.4549 - val_accuracy: 0.7952 - 404ms/epoch - 2ms/step\n",
      "Epoch 3/200\n",
      "259/259 - 0s - loss: 0.4612 - accuracy: 0.7804 - val_loss: 0.4482 - val_accuracy: 0.7947 - 383ms/epoch - 1ms/step\n",
      "Epoch 4/200\n",
      "259/259 - 0s - loss: 0.4542 - accuracy: 0.7836 - val_loss: 0.4449 - val_accuracy: 0.8005 - 357ms/epoch - 1ms/step\n",
      "Epoch 5/200\n",
      "259/259 - 0s - loss: 0.4504 - accuracy: 0.7822 - val_loss: 0.4488 - val_accuracy: 0.7942 - 353ms/epoch - 1ms/step\n",
      "Epoch 6/200\n",
      "259/259 - 1s - loss: 0.4467 - accuracy: 0.7864 - val_loss: 0.4412 - val_accuracy: 0.7981 - 534ms/epoch - 2ms/step\n",
      "Epoch 7/200\n",
      "259/259 - 0s - loss: 0.4440 - accuracy: 0.7863 - val_loss: 0.4395 - val_accuracy: 0.7971 - 442ms/epoch - 2ms/step\n",
      "Epoch 8/200\n",
      "259/259 - 0s - loss: 0.4399 - accuracy: 0.7933 - val_loss: 0.4366 - val_accuracy: 0.7995 - 392ms/epoch - 2ms/step\n",
      "Epoch 9/200\n",
      "259/259 - 0s - loss: 0.4385 - accuracy: 0.7902 - val_loss: 0.4392 - val_accuracy: 0.7966 - 369ms/epoch - 1ms/step\n",
      "Epoch 10/200\n",
      "259/259 - 0s - loss: 0.4355 - accuracy: 0.7948 - val_loss: 0.4369 - val_accuracy: 0.7990 - 369ms/epoch - 1ms/step\n",
      "Epoch 11/200\n",
      "259/259 - 0s - loss: 0.4334 - accuracy: 0.7961 - val_loss: 0.4332 - val_accuracy: 0.7981 - 493ms/epoch - 2ms/step\n",
      "Epoch 12/200\n",
      "259/259 - 0s - loss: 0.4312 - accuracy: 0.7972 - val_loss: 0.4339 - val_accuracy: 0.7971 - 353ms/epoch - 1ms/step\n",
      "Epoch 13/200\n",
      "259/259 - 0s - loss: 0.4278 - accuracy: 0.7992 - val_loss: 0.4353 - val_accuracy: 0.7937 - 357ms/epoch - 1ms/step\n",
      "Epoch 14/200\n",
      "259/259 - 0s - loss: 0.4266 - accuracy: 0.7985 - val_loss: 0.4328 - val_accuracy: 0.8024 - 361ms/epoch - 1ms/step\n",
      "Epoch 15/200\n",
      "259/259 - 0s - loss: 0.4261 - accuracy: 0.8031 - val_loss: 0.4328 - val_accuracy: 0.8014 - 357ms/epoch - 1ms/step\n",
      "Epoch 16/200\n",
      "259/259 - 0s - loss: 0.4240 - accuracy: 0.8009 - val_loss: 0.4314 - val_accuracy: 0.8053 - 375ms/epoch - 1ms/step\n",
      "Epoch 17/200\n",
      "259/259 - 0s - loss: 0.4214 - accuracy: 0.8021 - val_loss: 0.4312 - val_accuracy: 0.8048 - 367ms/epoch - 1ms/step\n",
      "Epoch 18/200\n",
      "259/259 - 0s - loss: 0.4206 - accuracy: 0.8029 - val_loss: 0.4298 - val_accuracy: 0.8082 - 362ms/epoch - 1ms/step\n",
      "Epoch 19/200\n",
      "259/259 - 0s - loss: 0.4195 - accuracy: 0.8045 - val_loss: 0.4296 - val_accuracy: 0.8097 - 368ms/epoch - 1ms/step\n",
      "Epoch 20/200\n",
      "259/259 - 0s - loss: 0.4178 - accuracy: 0.8055 - val_loss: 0.4327 - val_accuracy: 0.8068 - 365ms/epoch - 1ms/step\n",
      "Epoch 21/200\n",
      "259/259 - 0s - loss: 0.4169 - accuracy: 0.8074 - val_loss: 0.4355 - val_accuracy: 0.8029 - 357ms/epoch - 1ms/step\n",
      "Epoch 22/200\n",
      "259/259 - 0s - loss: 0.4168 - accuracy: 0.8054 - val_loss: 0.4341 - val_accuracy: 0.8014 - 412ms/epoch - 2ms/step\n",
      "Epoch 23/200\n",
      "259/259 - 0s - loss: 0.4151 - accuracy: 0.8083 - val_loss: 0.4328 - val_accuracy: 0.8043 - 456ms/epoch - 2ms/step\n",
      "Epoch 24/200\n",
      "259/259 - 0s - loss: 0.4139 - accuracy: 0.8066 - val_loss: 0.4332 - val_accuracy: 0.8019 - 461ms/epoch - 2ms/step\n",
      "Epoch 25/200\n",
      "259/259 - 0s - loss: 0.4139 - accuracy: 0.8083 - val_loss: 0.4301 - val_accuracy: 0.8058 - 370ms/epoch - 1ms/step\n",
      "Epoch 26/200\n",
      "259/259 - 0s - loss: 0.4129 - accuracy: 0.8113 - val_loss: 0.4309 - val_accuracy: 0.8068 - 456ms/epoch - 2ms/step\n",
      "Epoch 27/200\n",
      "259/259 - 0s - loss: 0.4108 - accuracy: 0.8090 - val_loss: 0.4298 - val_accuracy: 0.8082 - 445ms/epoch - 2ms/step\n",
      "Epoch 28/200\n",
      "259/259 - 1s - loss: 0.4105 - accuracy: 0.8107 - val_loss: 0.4270 - val_accuracy: 0.8126 - 529ms/epoch - 2ms/step\n",
      "Epoch 29/200\n",
      "259/259 - 0s - loss: 0.4090 - accuracy: 0.8138 - val_loss: 0.4306 - val_accuracy: 0.8077 - 366ms/epoch - 1ms/step\n",
      "Epoch 30/200\n",
      "259/259 - 0s - loss: 0.4086 - accuracy: 0.8136 - val_loss: 0.4291 - val_accuracy: 0.8058 - 370ms/epoch - 1ms/step\n",
      "Epoch 31/200\n",
      "259/259 - 0s - loss: 0.4087 - accuracy: 0.8146 - val_loss: 0.4305 - val_accuracy: 0.8053 - 362ms/epoch - 1ms/step\n",
      "Epoch 32/200\n",
      "259/259 - 0s - loss: 0.4082 - accuracy: 0.8136 - val_loss: 0.4271 - val_accuracy: 0.8048 - 374ms/epoch - 1ms/step\n",
      "Epoch 33/200\n",
      "259/259 - 1s - loss: 0.4069 - accuracy: 0.8146 - val_loss: 0.4266 - val_accuracy: 0.8092 - 559ms/epoch - 2ms/step\n",
      "Epoch 34/200\n",
      "259/259 - 0s - loss: 0.4060 - accuracy: 0.8148 - val_loss: 0.4283 - val_accuracy: 0.8121 - 371ms/epoch - 1ms/step\n",
      "Epoch 35/200\n",
      "259/259 - 0s - loss: 0.4060 - accuracy: 0.8143 - val_loss: 0.4295 - val_accuracy: 0.8014 - 475ms/epoch - 2ms/step\n",
      "Epoch 36/200\n",
      "259/259 - 0s - loss: 0.4049 - accuracy: 0.8148 - val_loss: 0.4274 - val_accuracy: 0.8145 - 399ms/epoch - 2ms/step\n",
      "Epoch 37/200\n",
      "259/259 - 0s - loss: 0.4041 - accuracy: 0.8161 - val_loss: 0.4268 - val_accuracy: 0.8077 - 366ms/epoch - 1ms/step\n",
      "Epoch 38/200\n",
      "259/259 - 0s - loss: 0.4044 - accuracy: 0.8124 - val_loss: 0.4262 - val_accuracy: 0.8111 - 492ms/epoch - 2ms/step\n",
      "Epoch 39/200\n",
      "259/259 - 1s - loss: 0.4036 - accuracy: 0.8180 - val_loss: 0.4272 - val_accuracy: 0.8106 - 603ms/epoch - 2ms/step\n",
      "Epoch 40/200\n",
      "259/259 - 1s - loss: 0.4023 - accuracy: 0.8151 - val_loss: 0.4302 - val_accuracy: 0.8126 - 587ms/epoch - 2ms/step\n",
      "Epoch 41/200\n",
      "259/259 - 1s - loss: 0.4018 - accuracy: 0.8169 - val_loss: 0.4324 - val_accuracy: 0.8092 - 636ms/epoch - 2ms/step\n",
      "Epoch 42/200\n",
      "259/259 - 1s - loss: 0.4011 - accuracy: 0.8157 - val_loss: 0.4269 - val_accuracy: 0.8130 - 562ms/epoch - 2ms/step\n",
      "Epoch 43/200\n",
      "259/259 - 1s - loss: 0.4011 - accuracy: 0.8178 - val_loss: 0.4263 - val_accuracy: 0.8155 - 644ms/epoch - 2ms/step\n",
      "Epoch 44/200\n",
      "259/259 - 1s - loss: 0.3996 - accuracy: 0.8183 - val_loss: 0.4267 - val_accuracy: 0.8106 - 863ms/epoch - 3ms/step\n",
      "Epoch 45/200\n",
      "259/259 - 1s - loss: 0.4002 - accuracy: 0.8169 - val_loss: 0.4284 - val_accuracy: 0.8077 - 821ms/epoch - 3ms/step\n",
      "Epoch 46/200\n",
      "259/259 - 1s - loss: 0.3993 - accuracy: 0.8190 - val_loss: 0.4282 - val_accuracy: 0.8145 - 551ms/epoch - 2ms/step\n",
      "Epoch 47/200\n",
      "259/259 - 1s - loss: 0.3991 - accuracy: 0.8184 - val_loss: 0.4262 - val_accuracy: 0.8106 - 1s/epoch - 5ms/step\n",
      "Epoch 48/200\n",
      "259/259 - 1s - loss: 0.3980 - accuracy: 0.8181 - val_loss: 0.4281 - val_accuracy: 0.8101 - 698ms/epoch - 3ms/step\n",
      "Epoch 49/200\n",
      "259/259 - 1s - loss: 0.3977 - accuracy: 0.8188 - val_loss: 0.4278 - val_accuracy: 0.8155 - 703ms/epoch - 3ms/step\n",
      "Epoch 50/200\n",
      "259/259 - 1s - loss: 0.3975 - accuracy: 0.8225 - val_loss: 0.4290 - val_accuracy: 0.8043 - 558ms/epoch - 2ms/step\n",
      "Epoch 51/200\n",
      "259/259 - 1s - loss: 0.3961 - accuracy: 0.8227 - val_loss: 0.4320 - val_accuracy: 0.8150 - 861ms/epoch - 3ms/step\n",
      "Epoch 52/200\n",
      "259/259 - 1s - loss: 0.3971 - accuracy: 0.8209 - val_loss: 0.4267 - val_accuracy: 0.8155 - 967ms/epoch - 4ms/step\n",
      "Epoch 53/200\n",
      "259/259 - 1s - loss: 0.3955 - accuracy: 0.8205 - val_loss: 0.4281 - val_accuracy: 0.8082 - 700ms/epoch - 3ms/step\n",
      "Epoch 54/200\n",
      "259/259 - 1s - loss: 0.3951 - accuracy: 0.8204 - val_loss: 0.4295 - val_accuracy: 0.8063 - 687ms/epoch - 3ms/step\n",
      "Epoch 55/200\n",
      "259/259 - 1s - loss: 0.3947 - accuracy: 0.8213 - val_loss: 0.4335 - val_accuracy: 0.8082 - 741ms/epoch - 3ms/step\n",
      "Epoch 56/200\n",
      "259/259 - 1s - loss: 0.3948 - accuracy: 0.8202 - val_loss: 0.4279 - val_accuracy: 0.8116 - 612ms/epoch - 2ms/step\n",
      "Epoch 57/200\n",
      "259/259 - 0s - loss: 0.3934 - accuracy: 0.8218 - val_loss: 0.4282 - val_accuracy: 0.8111 - 494ms/epoch - 2ms/step\n",
      "Epoch 58/200\n",
      "259/259 - 1s - loss: 0.3927 - accuracy: 0.8230 - val_loss: 0.4286 - val_accuracy: 0.8101 - 792ms/epoch - 3ms/step\n",
      "Epoch 59/200\n",
      "259/259 - 1s - loss: 0.3932 - accuracy: 0.8228 - val_loss: 0.4326 - val_accuracy: 0.8053 - 656ms/epoch - 3ms/step\n",
      "Epoch 60/200\n",
      "259/259 - 1s - loss: 0.3930 - accuracy: 0.8237 - val_loss: 0.4308 - val_accuracy: 0.8121 - 578ms/epoch - 2ms/step\n",
      "Epoch 61/200\n",
      "259/259 - 0s - loss: 0.3926 - accuracy: 0.8241 - val_loss: 0.4277 - val_accuracy: 0.8145 - 425ms/epoch - 2ms/step\n",
      "Epoch 62/200\n",
      "259/259 - 0s - loss: 0.3911 - accuracy: 0.8237 - val_loss: 0.4300 - val_accuracy: 0.8121 - 431ms/epoch - 2ms/step\n",
      "Epoch 63/200\n",
      "259/259 - 0s - loss: 0.3911 - accuracy: 0.8230 - val_loss: 0.4348 - val_accuracy: 0.8068 - 415ms/epoch - 2ms/step\n",
      "Epoch 64/200\n",
      "259/259 - 0s - loss: 0.3915 - accuracy: 0.8235 - val_loss: 0.4366 - val_accuracy: 0.8111 - 451ms/epoch - 2ms/step\n",
      "Epoch 65/200\n",
      "259/259 - 0s - loss: 0.3916 - accuracy: 0.8234 - val_loss: 0.4342 - val_accuracy: 0.8135 - 473ms/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/200\n",
      "259/259 - 1s - loss: 0.3918 - accuracy: 0.8239 - val_loss: 0.4344 - val_accuracy: 0.8101 - 709ms/epoch - 3ms/step\n",
      "Epoch 67/200\n",
      "259/259 - 0s - loss: 0.3887 - accuracy: 0.8269 - val_loss: 0.4318 - val_accuracy: 0.8116 - 448ms/epoch - 2ms/step\n",
      "Epoch 68/200\n",
      "259/259 - 1s - loss: 0.3889 - accuracy: 0.8258 - val_loss: 0.4304 - val_accuracy: 0.8169 - 574ms/epoch - 2ms/step\n",
      "Epoch 69/200\n",
      "259/259 - 0s - loss: 0.3884 - accuracy: 0.8287 - val_loss: 0.4337 - val_accuracy: 0.8082 - 448ms/epoch - 2ms/step\n",
      "Epoch 70/200\n",
      "259/259 - 1s - loss: 0.3895 - accuracy: 0.8275 - val_loss: 0.4325 - val_accuracy: 0.8130 - 568ms/epoch - 2ms/step\n",
      "Epoch 71/200\n",
      "259/259 - 1s - loss: 0.3881 - accuracy: 0.8253 - val_loss: 0.4317 - val_accuracy: 0.8106 - 614ms/epoch - 2ms/step\n",
      "Epoch 72/200\n",
      "259/259 - 0s - loss: 0.3877 - accuracy: 0.8271 - val_loss: 0.4314 - val_accuracy: 0.8155 - 475ms/epoch - 2ms/step\n",
      "Epoch 73/200\n",
      "259/259 - 1s - loss: 0.3875 - accuracy: 0.8264 - val_loss: 0.4326 - val_accuracy: 0.8092 - 519ms/epoch - 2ms/step\n",
      "Epoch 74/200\n",
      "259/259 - 0s - loss: 0.3858 - accuracy: 0.8258 - val_loss: 0.4354 - val_accuracy: 0.8116 - 489ms/epoch - 2ms/step\n",
      "Epoch 75/200\n",
      "259/259 - 0s - loss: 0.3874 - accuracy: 0.8266 - val_loss: 0.4316 - val_accuracy: 0.8130 - 423ms/epoch - 2ms/step\n",
      "Epoch 76/200\n",
      "259/259 - 0s - loss: 0.3863 - accuracy: 0.8252 - val_loss: 0.4309 - val_accuracy: 0.8121 - 411ms/epoch - 2ms/step\n",
      "Epoch 77/200\n",
      "259/259 - 0s - loss: 0.3853 - accuracy: 0.8276 - val_loss: 0.4315 - val_accuracy: 0.8116 - 420ms/epoch - 2ms/step\n",
      "Epoch 78/200\n",
      "259/259 - 0s - loss: 0.3859 - accuracy: 0.8281 - val_loss: 0.4322 - val_accuracy: 0.8135 - 414ms/epoch - 2ms/step\n",
      "Epoch 79/200\n",
      "259/259 - 1s - loss: 0.3852 - accuracy: 0.8271 - val_loss: 0.4314 - val_accuracy: 0.8116 - 511ms/epoch - 2ms/step\n",
      "Epoch 80/200\n",
      "259/259 - 1s - loss: 0.3837 - accuracy: 0.8285 - val_loss: 0.4344 - val_accuracy: 0.8097 - 552ms/epoch - 2ms/step\n",
      "Epoch 81/200\n",
      "259/259 - 1s - loss: 0.3836 - accuracy: 0.8299 - val_loss: 0.4331 - val_accuracy: 0.8126 - 680ms/epoch - 3ms/step\n",
      "Epoch 82/200\n",
      "259/259 - 1s - loss: 0.3842 - accuracy: 0.8274 - val_loss: 0.4335 - val_accuracy: 0.8116 - 748ms/epoch - 3ms/step\n",
      "Epoch 83/200\n",
      "259/259 - 1s - loss: 0.3847 - accuracy: 0.8263 - val_loss: 0.4345 - val_accuracy: 0.8087 - 600ms/epoch - 2ms/step\n",
      "Epoch 84/200\n",
      "259/259 - 1s - loss: 0.3841 - accuracy: 0.8292 - val_loss: 0.4346 - val_accuracy: 0.8101 - 624ms/epoch - 2ms/step\n",
      "Epoch 85/200\n",
      "259/259 - 1s - loss: 0.3842 - accuracy: 0.8304 - val_loss: 0.4348 - val_accuracy: 0.8087 - 503ms/epoch - 2ms/step\n",
      "Epoch 86/200\n",
      "259/259 - 1s - loss: 0.3822 - accuracy: 0.8308 - val_loss: 0.4356 - val_accuracy: 0.8135 - 515ms/epoch - 2ms/step\n",
      "Epoch 87/200\n",
      "259/259 - 1s - loss: 0.3826 - accuracy: 0.8277 - val_loss: 0.4370 - val_accuracy: 0.8087 - 513ms/epoch - 2ms/step\n",
      "Epoch 88/200\n",
      "259/259 - 1s - loss: 0.3830 - accuracy: 0.8282 - val_loss: 0.4333 - val_accuracy: 0.8116 - 604ms/epoch - 2ms/step\n",
      "Epoch 89/200\n",
      "259/259 - 1s - loss: 0.3824 - accuracy: 0.8285 - val_loss: 0.4370 - val_accuracy: 0.8077 - 624ms/epoch - 2ms/step\n",
      "Epoch 90/200\n",
      "259/259 - 1s - loss: 0.3830 - accuracy: 0.8294 - val_loss: 0.4344 - val_accuracy: 0.8077 - 627ms/epoch - 2ms/step\n",
      "Epoch 91/200\n",
      "259/259 - 1s - loss: 0.3817 - accuracy: 0.8291 - val_loss: 0.4364 - val_accuracy: 0.8126 - 705ms/epoch - 3ms/step\n",
      "Epoch 92/200\n",
      "259/259 - 1s - loss: 0.3821 - accuracy: 0.8298 - val_loss: 0.4339 - val_accuracy: 0.8159 - 704ms/epoch - 3ms/step\n",
      "Epoch 93/200\n",
      "259/259 - 1s - loss: 0.3813 - accuracy: 0.8303 - val_loss: 0.4392 - val_accuracy: 0.8058 - 603ms/epoch - 2ms/step\n",
      "Epoch 94/200\n",
      "259/259 - 1s - loss: 0.3815 - accuracy: 0.8299 - val_loss: 0.4362 - val_accuracy: 0.8106 - 566ms/epoch - 2ms/step\n",
      "Epoch 95/200\n",
      "259/259 - 0s - loss: 0.3811 - accuracy: 0.8305 - val_loss: 0.4365 - val_accuracy: 0.8101 - 434ms/epoch - 2ms/step\n",
      "Epoch 96/200\n",
      "259/259 - 1s - loss: 0.3807 - accuracy: 0.8294 - val_loss: 0.4402 - val_accuracy: 0.8053 - 639ms/epoch - 2ms/step\n",
      "Epoch 97/200\n",
      "259/259 - 1s - loss: 0.3805 - accuracy: 0.8292 - val_loss: 0.4424 - val_accuracy: 0.8043 - 695ms/epoch - 3ms/step\n",
      "Epoch 98/200\n",
      "259/259 - 1s - loss: 0.3799 - accuracy: 0.8302 - val_loss: 0.4395 - val_accuracy: 0.8101 - 519ms/epoch - 2ms/step\n",
      "Epoch 99/200\n",
      "259/259 - 1s - loss: 0.3808 - accuracy: 0.8309 - val_loss: 0.4379 - val_accuracy: 0.8077 - 533ms/epoch - 2ms/step\n",
      "Epoch 100/200\n",
      "259/259 - 0s - loss: 0.3785 - accuracy: 0.8318 - val_loss: 0.4397 - val_accuracy: 0.8116 - 449ms/epoch - 2ms/step\n",
      "Epoch 101/200\n",
      "259/259 - 0s - loss: 0.3803 - accuracy: 0.8323 - val_loss: 0.4380 - val_accuracy: 0.8126 - 416ms/epoch - 2ms/step\n",
      "Epoch 102/200\n",
      "259/259 - 1s - loss: 0.3789 - accuracy: 0.8311 - val_loss: 0.4399 - val_accuracy: 0.8063 - 524ms/epoch - 2ms/step\n",
      "Epoch 103/200\n",
      "259/259 - 1s - loss: 0.3786 - accuracy: 0.8316 - val_loss: 0.4394 - val_accuracy: 0.8111 - 559ms/epoch - 2ms/step\n",
      "Epoch 104/200\n",
      "259/259 - 0s - loss: 0.3788 - accuracy: 0.8306 - val_loss: 0.4365 - val_accuracy: 0.8063 - 452ms/epoch - 2ms/step\n",
      "Epoch 105/200\n",
      "259/259 - 0s - loss: 0.3784 - accuracy: 0.8321 - val_loss: 0.4371 - val_accuracy: 0.8087 - 423ms/epoch - 2ms/step\n",
      "Epoch 106/200\n",
      "259/259 - 0s - loss: 0.3774 - accuracy: 0.8339 - val_loss: 0.4421 - val_accuracy: 0.8029 - 420ms/epoch - 2ms/step\n",
      "Epoch 107/200\n",
      "259/259 - 0s - loss: 0.3787 - accuracy: 0.8324 - val_loss: 0.4418 - val_accuracy: 0.8063 - 417ms/epoch - 2ms/step\n",
      "Epoch 108/200\n",
      "259/259 - 0s - loss: 0.3779 - accuracy: 0.8321 - val_loss: 0.4423 - val_accuracy: 0.7990 - 419ms/epoch - 2ms/step\n",
      "Epoch 109/200\n",
      "259/259 - 0s - loss: 0.3766 - accuracy: 0.8314 - val_loss: 0.4426 - val_accuracy: 0.8068 - 424ms/epoch - 2ms/step\n",
      "Epoch 110/200\n",
      "259/259 - 0s - loss: 0.3773 - accuracy: 0.8347 - val_loss: 0.4419 - val_accuracy: 0.8024 - 411ms/epoch - 2ms/step\n",
      "Epoch 111/200\n",
      "259/259 - 0s - loss: 0.3762 - accuracy: 0.8333 - val_loss: 0.4410 - val_accuracy: 0.8048 - 418ms/epoch - 2ms/step\n",
      "Epoch 112/200\n",
      "259/259 - 0s - loss: 0.3763 - accuracy: 0.8326 - val_loss: 0.4405 - val_accuracy: 0.8097 - 416ms/epoch - 2ms/step\n",
      "Epoch 113/200\n",
      "259/259 - 0s - loss: 0.3753 - accuracy: 0.8334 - val_loss: 0.4406 - val_accuracy: 0.8092 - 418ms/epoch - 2ms/step\n",
      "Epoch 114/200\n",
      "259/259 - 0s - loss: 0.3755 - accuracy: 0.8320 - val_loss: 0.4414 - val_accuracy: 0.8048 - 424ms/epoch - 2ms/step\n",
      "Epoch 115/200\n",
      "259/259 - 0s - loss: 0.3763 - accuracy: 0.8327 - val_loss: 0.4422 - val_accuracy: 0.8048 - 412ms/epoch - 2ms/step\n",
      "Epoch 116/200\n",
      "259/259 - 0s - loss: 0.3755 - accuracy: 0.8323 - val_loss: 0.4421 - val_accuracy: 0.8029 - 415ms/epoch - 2ms/step\n",
      "Epoch 117/200\n",
      "259/259 - 0s - loss: 0.3764 - accuracy: 0.8329 - val_loss: 0.4416 - val_accuracy: 0.8068 - 422ms/epoch - 2ms/step\n",
      "Epoch 118/200\n",
      "259/259 - 0s - loss: 0.3753 - accuracy: 0.8326 - val_loss: 0.4429 - val_accuracy: 0.8029 - 433ms/epoch - 2ms/step\n",
      "Epoch 119/200\n",
      "259/259 - 0s - loss: 0.3753 - accuracy: 0.8331 - val_loss: 0.4424 - val_accuracy: 0.8077 - 432ms/epoch - 2ms/step\n",
      "Epoch 120/200\n",
      "259/259 - 0s - loss: 0.3747 - accuracy: 0.8353 - val_loss: 0.4424 - val_accuracy: 0.8048 - 427ms/epoch - 2ms/step\n",
      "Epoch 121/200\n",
      "259/259 - 0s - loss: 0.3757 - accuracy: 0.8328 - val_loss: 0.4427 - val_accuracy: 0.8053 - 415ms/epoch - 2ms/step\n",
      "Epoch 122/200\n",
      "259/259 - 0s - loss: 0.3735 - accuracy: 0.8361 - val_loss: 0.4420 - val_accuracy: 0.8077 - 416ms/epoch - 2ms/step\n",
      "Epoch 123/200\n",
      "259/259 - 0s - loss: 0.3738 - accuracy: 0.8345 - val_loss: 0.4500 - val_accuracy: 0.8024 - 413ms/epoch - 2ms/step\n",
      "Epoch 124/200\n",
      "259/259 - 0s - loss: 0.3734 - accuracy: 0.8361 - val_loss: 0.4439 - val_accuracy: 0.8082 - 438ms/epoch - 2ms/step\n",
      "Epoch 125/200\n",
      "259/259 - 0s - loss: 0.3733 - accuracy: 0.8353 - val_loss: 0.4482 - val_accuracy: 0.8024 - 423ms/epoch - 2ms/step\n",
      "Epoch 126/200\n",
      "259/259 - 0s - loss: 0.3742 - accuracy: 0.8317 - val_loss: 0.4425 - val_accuracy: 0.8063 - 418ms/epoch - 2ms/step\n",
      "Epoch 127/200\n",
      "259/259 - 0s - loss: 0.3740 - accuracy: 0.8339 - val_loss: 0.4461 - val_accuracy: 0.8072 - 424ms/epoch - 2ms/step\n",
      "Epoch 128/200\n",
      "259/259 - 0s - loss: 0.3730 - accuracy: 0.8361 - val_loss: 0.4439 - val_accuracy: 0.8034 - 419ms/epoch - 2ms/step\n",
      "Epoch 129/200\n",
      "259/259 - 0s - loss: 0.3717 - accuracy: 0.8370 - val_loss: 0.4452 - val_accuracy: 0.8063 - 435ms/epoch - 2ms/step\n",
      "Epoch 130/200\n",
      "259/259 - 0s - loss: 0.3731 - accuracy: 0.8352 - val_loss: 0.4455 - val_accuracy: 0.8072 - 426ms/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/200\n",
      "259/259 - 0s - loss: 0.3718 - accuracy: 0.8363 - val_loss: 0.4435 - val_accuracy: 0.8063 - 409ms/epoch - 2ms/step\n",
      "Epoch 132/200\n",
      "259/259 - 0s - loss: 0.3717 - accuracy: 0.8363 - val_loss: 0.4498 - val_accuracy: 0.8053 - 410ms/epoch - 2ms/step\n",
      "Epoch 133/200\n",
      "259/259 - 0s - loss: 0.3723 - accuracy: 0.8352 - val_loss: 0.4451 - val_accuracy: 0.8058 - 411ms/epoch - 2ms/step\n",
      "Epoch 134/200\n",
      "259/259 - 0s - loss: 0.3706 - accuracy: 0.8346 - val_loss: 0.4445 - val_accuracy: 0.8058 - 430ms/epoch - 2ms/step\n",
      "Epoch 135/200\n",
      "259/259 - 0s - loss: 0.3715 - accuracy: 0.8352 - val_loss: 0.4443 - val_accuracy: 0.8048 - 419ms/epoch - 2ms/step\n",
      "Epoch 136/200\n",
      "259/259 - 0s - loss: 0.3712 - accuracy: 0.8373 - val_loss: 0.4513 - val_accuracy: 0.7971 - 407ms/epoch - 2ms/step\n",
      "Epoch 137/200\n",
      "259/259 - 0s - loss: 0.3708 - accuracy: 0.8351 - val_loss: 0.4489 - val_accuracy: 0.8053 - 417ms/epoch - 2ms/step\n",
      "Epoch 138/200\n",
      "259/259 - 0s - loss: 0.3705 - accuracy: 0.8357 - val_loss: 0.4426 - val_accuracy: 0.8121 - 404ms/epoch - 2ms/step\n",
      "Epoch 139/200\n",
      "259/259 - 0s - loss: 0.3713 - accuracy: 0.8343 - val_loss: 0.4447 - val_accuracy: 0.8043 - 434ms/epoch - 2ms/step\n",
      "Epoch 140/200\n",
      "259/259 - 0s - loss: 0.3705 - accuracy: 0.8353 - val_loss: 0.4465 - val_accuracy: 0.8039 - 407ms/epoch - 2ms/step\n",
      "Epoch 141/200\n",
      "259/259 - 0s - loss: 0.3697 - accuracy: 0.8360 - val_loss: 0.4501 - val_accuracy: 0.8053 - 419ms/epoch - 2ms/step\n",
      "Epoch 142/200\n",
      "259/259 - 0s - loss: 0.3700 - accuracy: 0.8372 - val_loss: 0.4492 - val_accuracy: 0.8019 - 416ms/epoch - 2ms/step\n",
      "Epoch 143/200\n",
      "259/259 - 0s - loss: 0.3688 - accuracy: 0.8356 - val_loss: 0.4451 - val_accuracy: 0.8097 - 424ms/epoch - 2ms/step\n",
      "Epoch 144/200\n",
      "259/259 - 0s - loss: 0.3694 - accuracy: 0.8373 - val_loss: 0.4474 - val_accuracy: 0.8063 - 489ms/epoch - 2ms/step\n",
      "Epoch 145/200\n",
      "259/259 - 1s - loss: 0.3689 - accuracy: 0.8367 - val_loss: 0.4588 - val_accuracy: 0.8019 - 653ms/epoch - 3ms/step\n",
      "Epoch 146/200\n",
      "259/259 - 1s - loss: 0.3715 - accuracy: 0.8350 - val_loss: 0.4467 - val_accuracy: 0.8063 - 775ms/epoch - 3ms/step\n",
      "Epoch 147/200\n",
      "259/259 - 1s - loss: 0.3676 - accuracy: 0.8393 - val_loss: 0.4476 - val_accuracy: 0.8164 - 760ms/epoch - 3ms/step\n",
      "Epoch 148/200\n",
      "259/259 - 1s - loss: 0.3683 - accuracy: 0.8388 - val_loss: 0.4482 - val_accuracy: 0.8130 - 509ms/epoch - 2ms/step\n",
      "Epoch 149/200\n",
      "259/259 - 0s - loss: 0.3680 - accuracy: 0.8399 - val_loss: 0.4495 - val_accuracy: 0.8068 - 443ms/epoch - 2ms/step\n",
      "Epoch 150/200\n",
      "259/259 - 0s - loss: 0.3688 - accuracy: 0.8387 - val_loss: 0.4491 - val_accuracy: 0.8077 - 440ms/epoch - 2ms/step\n",
      "Epoch 151/200\n",
      "259/259 - 1s - loss: 0.3677 - accuracy: 0.8372 - val_loss: 0.4504 - val_accuracy: 0.8097 - 690ms/epoch - 3ms/step\n",
      "Epoch 152/200\n",
      "259/259 - 1s - loss: 0.3672 - accuracy: 0.8362 - val_loss: 0.4460 - val_accuracy: 0.8101 - 636ms/epoch - 2ms/step\n",
      "Epoch 153/200\n",
      "259/259 - 1s - loss: 0.3675 - accuracy: 0.8388 - val_loss: 0.4492 - val_accuracy: 0.8092 - 609ms/epoch - 2ms/step\n",
      "Epoch 154/200\n",
      "259/259 - 1s - loss: 0.3668 - accuracy: 0.8381 - val_loss: 0.4474 - val_accuracy: 0.8082 - 705ms/epoch - 3ms/step\n",
      "Epoch 155/200\n",
      "259/259 - 1s - loss: 0.3674 - accuracy: 0.8402 - val_loss: 0.4511 - val_accuracy: 0.8034 - 578ms/epoch - 2ms/step\n",
      "Epoch 156/200\n",
      "259/259 - 1s - loss: 0.3662 - accuracy: 0.8419 - val_loss: 0.4465 - val_accuracy: 0.8106 - 681ms/epoch - 3ms/step\n",
      "Epoch 157/200\n",
      "259/259 - 1s - loss: 0.3668 - accuracy: 0.8380 - val_loss: 0.4503 - val_accuracy: 0.8092 - 532ms/epoch - 2ms/step\n",
      "Epoch 158/200\n",
      "259/259 - 1s - loss: 0.3676 - accuracy: 0.8397 - val_loss: 0.4486 - val_accuracy: 0.8039 - 699ms/epoch - 3ms/step\n",
      "Epoch 159/200\n",
      "259/259 - 1s - loss: 0.3671 - accuracy: 0.8381 - val_loss: 0.4463 - val_accuracy: 0.8101 - 683ms/epoch - 3ms/step\n",
      "Epoch 160/200\n",
      "259/259 - 1s - loss: 0.3658 - accuracy: 0.8367 - val_loss: 0.4492 - val_accuracy: 0.8039 - 592ms/epoch - 2ms/step\n",
      "Epoch 161/200\n",
      "259/259 - 1s - loss: 0.3663 - accuracy: 0.8374 - val_loss: 0.4449 - val_accuracy: 0.8097 - 590ms/epoch - 2ms/step\n",
      "Epoch 162/200\n",
      "259/259 - 1s - loss: 0.3660 - accuracy: 0.8367 - val_loss: 0.4491 - val_accuracy: 0.8068 - 640ms/epoch - 2ms/step\n",
      "Epoch 163/200\n",
      "259/259 - 1s - loss: 0.3649 - accuracy: 0.8372 - val_loss: 0.4514 - val_accuracy: 0.8053 - 635ms/epoch - 2ms/step\n",
      "Epoch 164/200\n",
      "259/259 - 1s - loss: 0.3659 - accuracy: 0.8393 - val_loss: 0.4477 - val_accuracy: 0.8150 - 595ms/epoch - 2ms/step\n",
      "Epoch 165/200\n",
      "259/259 - 0s - loss: 0.3643 - accuracy: 0.8397 - val_loss: 0.4478 - val_accuracy: 0.8169 - 489ms/epoch - 2ms/step\n",
      "Epoch 166/200\n",
      "259/259 - 0s - loss: 0.3666 - accuracy: 0.8350 - val_loss: 0.4442 - val_accuracy: 0.8135 - 486ms/epoch - 2ms/step\n",
      "Epoch 167/200\n",
      "259/259 - 0s - loss: 0.3641 - accuracy: 0.8388 - val_loss: 0.4469 - val_accuracy: 0.8126 - 492ms/epoch - 2ms/step\n",
      "Epoch 168/200\n",
      "259/259 - 1s - loss: 0.3645 - accuracy: 0.8385 - val_loss: 0.4467 - val_accuracy: 0.8087 - 511ms/epoch - 2ms/step\n",
      "Epoch 169/200\n",
      "259/259 - 0s - loss: 0.3651 - accuracy: 0.8419 - val_loss: 0.4464 - val_accuracy: 0.8101 - 479ms/epoch - 2ms/step\n",
      "Epoch 170/200\n",
      "259/259 - 0s - loss: 0.3650 - accuracy: 0.8421 - val_loss: 0.4452 - val_accuracy: 0.8140 - 483ms/epoch - 2ms/step\n",
      "Epoch 171/200\n",
      "259/259 - 0s - loss: 0.3650 - accuracy: 0.8399 - val_loss: 0.4472 - val_accuracy: 0.8101 - 500ms/epoch - 2ms/step\n",
      "Epoch 172/200\n",
      "259/259 - 1s - loss: 0.3628 - accuracy: 0.8396 - val_loss: 0.4519 - val_accuracy: 0.8077 - 578ms/epoch - 2ms/step\n",
      "Epoch 173/200\n",
      "259/259 - 0s - loss: 0.3636 - accuracy: 0.8401 - val_loss: 0.4517 - val_accuracy: 0.8087 - 484ms/epoch - 2ms/step\n",
      "Epoch 174/200\n",
      "259/259 - 0s - loss: 0.3650 - accuracy: 0.8408 - val_loss: 0.4470 - val_accuracy: 0.8068 - 473ms/epoch - 2ms/step\n",
      "Epoch 175/200\n",
      "259/259 - 1s - loss: 0.3633 - accuracy: 0.8411 - val_loss: 0.4494 - val_accuracy: 0.8116 - 680ms/epoch - 3ms/step\n",
      "Epoch 176/200\n",
      "259/259 - 1s - loss: 0.3633 - accuracy: 0.8388 - val_loss: 0.4551 - val_accuracy: 0.8034 - 718ms/epoch - 3ms/step\n",
      "Epoch 177/200\n",
      "259/259 - 1s - loss: 0.3637 - accuracy: 0.8411 - val_loss: 0.4457 - val_accuracy: 0.8150 - 651ms/epoch - 3ms/step\n",
      "Epoch 178/200\n",
      "259/259 - 1s - loss: 0.3646 - accuracy: 0.8390 - val_loss: 0.4483 - val_accuracy: 0.8048 - 576ms/epoch - 2ms/step\n",
      "Epoch 179/200\n",
      "259/259 - 1s - loss: 0.3635 - accuracy: 0.8409 - val_loss: 0.4501 - val_accuracy: 0.8101 - 779ms/epoch - 3ms/step\n",
      "Epoch 180/200\n",
      "259/259 - 1s - loss: 0.3633 - accuracy: 0.8424 - val_loss: 0.4509 - val_accuracy: 0.8068 - 744ms/epoch - 3ms/step\n",
      "Epoch 181/200\n",
      "259/259 - 1s - loss: 0.3633 - accuracy: 0.8407 - val_loss: 0.4473 - val_accuracy: 0.8077 - 545ms/epoch - 2ms/step\n",
      "Epoch 182/200\n",
      "259/259 - 1s - loss: 0.3624 - accuracy: 0.8424 - val_loss: 0.4514 - val_accuracy: 0.8082 - 529ms/epoch - 2ms/step\n",
      "Epoch 183/200\n",
      "259/259 - 1s - loss: 0.3648 - accuracy: 0.8395 - val_loss: 0.4522 - val_accuracy: 0.8034 - 715ms/epoch - 3ms/step\n",
      "Epoch 184/200\n",
      "259/259 - 1s - loss: 0.3628 - accuracy: 0.8407 - val_loss: 0.4461 - val_accuracy: 0.8126 - 633ms/epoch - 2ms/step\n",
      "Epoch 185/200\n",
      "259/259 - 1s - loss: 0.3624 - accuracy: 0.8427 - val_loss: 0.4467 - val_accuracy: 0.8101 - 719ms/epoch - 3ms/step\n",
      "Epoch 186/200\n",
      "259/259 - 1s - loss: 0.3622 - accuracy: 0.8404 - val_loss: 0.4527 - val_accuracy: 0.8039 - 701ms/epoch - 3ms/step\n",
      "Epoch 187/200\n",
      "259/259 - 1s - loss: 0.3624 - accuracy: 0.8415 - val_loss: 0.4521 - val_accuracy: 0.8039 - 675ms/epoch - 3ms/step\n",
      "Epoch 188/200\n",
      "259/259 - 1s - loss: 0.3618 - accuracy: 0.8409 - val_loss: 0.4490 - val_accuracy: 0.8068 - 536ms/epoch - 2ms/step\n",
      "Epoch 189/200\n",
      "259/259 - 0s - loss: 0.3620 - accuracy: 0.8409 - val_loss: 0.4527 - val_accuracy: 0.8155 - 443ms/epoch - 2ms/step\n",
      "Epoch 190/200\n",
      "259/259 - 1s - loss: 0.3628 - accuracy: 0.8401 - val_loss: 0.4517 - val_accuracy: 0.8039 - 514ms/epoch - 2ms/step\n",
      "Epoch 191/200\n",
      "259/259 - 0s - loss: 0.3610 - accuracy: 0.8407 - val_loss: 0.4464 - val_accuracy: 0.8184 - 419ms/epoch - 2ms/step\n",
      "Epoch 192/200\n",
      "259/259 - 0s - loss: 0.3612 - accuracy: 0.8416 - val_loss: 0.4520 - val_accuracy: 0.8082 - 422ms/epoch - 2ms/step\n",
      "Epoch 193/200\n",
      "259/259 - 1s - loss: 0.3621 - accuracy: 0.8409 - val_loss: 0.4468 - val_accuracy: 0.8116 - 537ms/epoch - 2ms/step\n",
      "Epoch 194/200\n",
      "259/259 - 0s - loss: 0.3608 - accuracy: 0.8427 - val_loss: 0.4468 - val_accuracy: 0.8106 - 414ms/epoch - 2ms/step\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259/259 - 1s - loss: 0.3616 - accuracy: 0.8408 - val_loss: 0.4473 - val_accuracy: 0.8116 - 537ms/epoch - 2ms/step\n",
      "Epoch 196/200\n",
      "259/259 - 1s - loss: 0.3608 - accuracy: 0.8442 - val_loss: 0.4527 - val_accuracy: 0.8077 - 512ms/epoch - 2ms/step\n",
      "Epoch 197/200\n",
      "259/259 - 1s - loss: 0.3609 - accuracy: 0.8414 - val_loss: 0.4475 - val_accuracy: 0.8116 - 523ms/epoch - 2ms/step\n",
      "Epoch 198/200\n",
      "259/259 - 1s - loss: 0.3603 - accuracy: 0.8427 - val_loss: 0.4517 - val_accuracy: 0.8053 - 535ms/epoch - 2ms/step\n",
      "Epoch 199/200\n",
      "259/259 - 1s - loss: 0.3602 - accuracy: 0.8422 - val_loss: 0.4528 - val_accuracy: 0.8155 - 526ms/epoch - 2ms/step\n",
      "Epoch 200/200\n",
      "259/259 - 1s - loss: 0.3603 - accuracy: 0.8387 - val_loss: 0.4532 - val_accuracy: 0.8024 - 533ms/epoch - 2ms/step\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[0 1 1 ... 1 1 0]\n",
      "Accuracy: 0.8024154589371981\n",
      "Precision: 0.8471528471528471\n",
      "Recall: 0.7681159420289855\n",
      "f1-score: 0.8057007125890735\n",
      "rmse: 0.4445048268160897\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(18, input_dim=24, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history=model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=200,\n",
    "          verbose=2,\n",
    "          validation_data=(X_test, y_test)) \n",
    "                \n",
    "y_pred = model.predict(X_test)\n",
    "pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(pred)\n",
    "\n",
    "a=accuracy_score(pred, y_test)\n",
    "\n",
    "precision=precision_score(pred,y_test)\n",
    "recall=recall_score(pred,y_test)\n",
    "f1=(2*(precision*recall))/(precision+recall)\n",
    "rmse=math.sqrt(mean_squared_error(y_test,pred))\n",
    "#Printthe accuracy, precision, recall, and F1 score of the result\n",
    "\n",
    "print(\"Accuracy:\",a)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"Recall:\",recall)\n",
    "print(\"f1-score:\", f1)\n",
    "print(\"rmse:\", rmse)\n",
    "\n",
    "#Plot the loss curve\n",
    "plt.plot(history.history['loss']) \n",
    "plt.plot(history.history['val_loss']) \n",
    "plt.title('Model loss') \n",
    "plt.ylabel('Loss') \n",
    "plt.xlabel('Epoch') \n",
    "plt.legend(['Train', 'Test'], loc='upper left') \n",
    "plt.show()\n",
    "\n",
    "#Plot the accurcy curve\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c723e283",
   "metadata": {},
   "source": [
    "# Neural Network with Hyper Parameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06178702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "259/259 - 1s - loss: 0.7355 - accuracy: 0.7043 - val_loss: 0.4712 - val_accuracy: 0.7894 - 830ms/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "259/259 - 0s - loss: 0.4752 - accuracy: 0.7758 - val_loss: 0.4538 - val_accuracy: 0.7932 - 321ms/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "259/259 - 0s - loss: 0.4647 - accuracy: 0.7775 - val_loss: 0.4488 - val_accuracy: 0.8014 - 347ms/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "259/259 - 0s - loss: 0.4603 - accuracy: 0.7811 - val_loss: 0.4447 - val_accuracy: 0.7976 - 427ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "259/259 - 0s - loss: 0.4553 - accuracy: 0.7862 - val_loss: 0.4423 - val_accuracy: 0.7976 - 391ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "259/259 - 0s - loss: 0.4516 - accuracy: 0.7855 - val_loss: 0.4402 - val_accuracy: 0.7971 - 374ms/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "259/259 - 0s - loss: 0.4485 - accuracy: 0.7856 - val_loss: 0.4380 - val_accuracy: 0.7961 - 332ms/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "259/259 - 0s - loss: 0.4458 - accuracy: 0.7869 - val_loss: 0.4354 - val_accuracy: 0.8019 - 311ms/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "259/259 - 0s - loss: 0.4414 - accuracy: 0.7885 - val_loss: 0.4370 - val_accuracy: 0.7966 - 319ms/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "259/259 - 0s - loss: 0.4378 - accuracy: 0.7897 - val_loss: 0.4314 - val_accuracy: 0.8014 - 322ms/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "259/259 - 0s - loss: 0.4347 - accuracy: 0.7944 - val_loss: 0.4305 - val_accuracy: 0.8034 - 317ms/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "259/259 - 0s - loss: 0.4339 - accuracy: 0.7946 - val_loss: 0.4292 - val_accuracy: 0.7995 - 321ms/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "259/259 - 0s - loss: 0.4312 - accuracy: 0.7964 - val_loss: 0.4299 - val_accuracy: 0.8005 - 319ms/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "259/259 - 0s - loss: 0.4290 - accuracy: 0.7981 - val_loss: 0.4303 - val_accuracy: 0.8077 - 311ms/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "259/259 - 0s - loss: 0.4264 - accuracy: 0.7973 - val_loss: 0.4412 - val_accuracy: 0.7990 - 328ms/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "259/259 - 0s - loss: 0.4265 - accuracy: 0.7991 - val_loss: 0.4295 - val_accuracy: 0.8092 - 320ms/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "259/259 - 0s - loss: 0.4230 - accuracy: 0.7979 - val_loss: 0.4374 - val_accuracy: 0.7928 - 310ms/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "259/259 - 0s - loss: 0.4217 - accuracy: 0.7997 - val_loss: 0.4352 - val_accuracy: 0.7986 - 310ms/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "259/259 - 0s - loss: 0.4207 - accuracy: 0.8042 - val_loss: 0.4295 - val_accuracy: 0.8029 - 330ms/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "259/259 - 0s - loss: 0.4198 - accuracy: 0.8015 - val_loss: 0.4261 - val_accuracy: 0.8039 - 320ms/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "259/259 - 0s - loss: 0.4191 - accuracy: 0.8037 - val_loss: 0.4306 - val_accuracy: 0.7957 - 330ms/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "259/259 - 0s - loss: 0.4177 - accuracy: 0.8015 - val_loss: 0.4265 - val_accuracy: 0.8029 - 313ms/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "259/259 - 0s - loss: 0.4162 - accuracy: 0.8039 - val_loss: 0.4255 - val_accuracy: 0.8092 - 324ms/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "259/259 - 0s - loss: 0.4158 - accuracy: 0.8064 - val_loss: 0.4338 - val_accuracy: 0.8005 - 380ms/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "259/259 - 0s - loss: 0.4139 - accuracy: 0.8059 - val_loss: 0.4331 - val_accuracy: 0.8014 - 310ms/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "259/259 - 0s - loss: 0.4131 - accuracy: 0.8070 - val_loss: 0.4271 - val_accuracy: 0.8005 - 320ms/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "259/259 - 0s - loss: 0.4116 - accuracy: 0.8082 - val_loss: 0.4272 - val_accuracy: 0.8019 - 340ms/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "259/259 - 0s - loss: 0.4118 - accuracy: 0.8099 - val_loss: 0.4274 - val_accuracy: 0.8048 - 350ms/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "259/259 - 0s - loss: 0.4100 - accuracy: 0.8096 - val_loss: 0.4264 - val_accuracy: 0.8077 - 311ms/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "259/259 - 0s - loss: 0.4077 - accuracy: 0.8086 - val_loss: 0.4294 - val_accuracy: 0.8087 - 310ms/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "259/259 - 1s - loss: 0.4083 - accuracy: 0.8117 - val_loss: 0.4300 - val_accuracy: 0.8077 - 681ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "259/259 - 1s - loss: 0.4069 - accuracy: 0.8112 - val_loss: 0.4269 - val_accuracy: 0.8034 - 656ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "259/259 - 0s - loss: 0.4053 - accuracy: 0.8126 - val_loss: 0.4252 - val_accuracy: 0.8126 - 458ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "259/259 - 0s - loss: 0.4060 - accuracy: 0.8129 - val_loss: 0.4260 - val_accuracy: 0.8087 - 453ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "259/259 - 0s - loss: 0.4046 - accuracy: 0.8135 - val_loss: 0.4300 - val_accuracy: 0.8039 - 486ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "259/259 - 0s - loss: 0.4031 - accuracy: 0.8105 - val_loss: 0.4264 - val_accuracy: 0.8135 - 403ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "259/259 - 1s - loss: 0.4044 - accuracy: 0.8140 - val_loss: 0.4325 - val_accuracy: 0.8072 - 561ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "259/259 - 0s - loss: 0.4024 - accuracy: 0.8154 - val_loss: 0.4272 - val_accuracy: 0.8068 - 399ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "259/259 - 0s - loss: 0.4019 - accuracy: 0.8135 - val_loss: 0.4272 - val_accuracy: 0.8097 - 470ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "259/259 - 0s - loss: 0.4009 - accuracy: 0.8149 - val_loss: 0.4254 - val_accuracy: 0.8111 - 487ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "259/259 - 0s - loss: 0.3997 - accuracy: 0.8172 - val_loss: 0.4260 - val_accuracy: 0.8101 - 488ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "259/259 - 0s - loss: 0.3991 - accuracy: 0.8159 - val_loss: 0.4242 - val_accuracy: 0.8087 - 382ms/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "259/259 - 0s - loss: 0.3991 - accuracy: 0.8188 - val_loss: 0.4266 - val_accuracy: 0.8140 - 466ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "259/259 - 0s - loss: 0.3970 - accuracy: 0.8175 - val_loss: 0.4277 - val_accuracy: 0.8121 - 389ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "259/259 - 0s - loss: 0.3966 - accuracy: 0.8167 - val_loss: 0.4277 - val_accuracy: 0.8087 - 413ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "259/259 - 0s - loss: 0.3960 - accuracy: 0.8198 - val_loss: 0.4276 - val_accuracy: 0.8101 - 354ms/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "259/259 - 0s - loss: 0.3934 - accuracy: 0.8201 - val_loss: 0.4243 - val_accuracy: 0.8155 - 329ms/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "259/259 - 0s - loss: 0.3925 - accuracy: 0.8198 - val_loss: 0.4229 - val_accuracy: 0.8184 - 335ms/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "259/259 - 0s - loss: 0.3919 - accuracy: 0.8210 - val_loss: 0.4222 - val_accuracy: 0.8208 - 329ms/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "259/259 - 0s - loss: 0.3916 - accuracy: 0.8224 - val_loss: 0.4263 - val_accuracy: 0.8135 - 325ms/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "259/259 - 0s - loss: 0.3901 - accuracy: 0.8207 - val_loss: 0.4282 - val_accuracy: 0.8116 - 321ms/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "259/259 - 0s - loss: 0.3906 - accuracy: 0.8240 - val_loss: 0.4284 - val_accuracy: 0.8092 - 322ms/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "259/259 - 0s - loss: 0.3892 - accuracy: 0.8209 - val_loss: 0.4278 - val_accuracy: 0.8164 - 341ms/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "259/259 - 0s - loss: 0.3873 - accuracy: 0.8235 - val_loss: 0.4228 - val_accuracy: 0.8179 - 320ms/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "259/259 - 0s - loss: 0.3887 - accuracy: 0.8234 - val_loss: 0.4284 - val_accuracy: 0.8155 - 320ms/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "259/259 - 0s - loss: 0.3866 - accuracy: 0.8235 - val_loss: 0.4318 - val_accuracy: 0.8039 - 345ms/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "259/259 - 0s - loss: 0.3865 - accuracy: 0.8216 - val_loss: 0.4241 - val_accuracy: 0.8164 - 334ms/epoch - 1ms/step\n",
      "Epoch 58/100\n",
      "259/259 - 0s - loss: 0.3860 - accuracy: 0.8236 - val_loss: 0.4285 - val_accuracy: 0.8140 - 360ms/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "259/259 - 0s - loss: 0.3849 - accuracy: 0.8264 - val_loss: 0.4263 - val_accuracy: 0.8155 - 388ms/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "259/259 - 0s - loss: 0.3859 - accuracy: 0.8241 - val_loss: 0.4233 - val_accuracy: 0.8193 - 362ms/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "259/259 - 0s - loss: 0.3836 - accuracy: 0.8252 - val_loss: 0.4247 - val_accuracy: 0.8159 - 358ms/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "259/259 - 0s - loss: 0.3835 - accuracy: 0.8275 - val_loss: 0.4262 - val_accuracy: 0.8150 - 349ms/epoch - 1ms/step\n",
      "Epoch 63/100\n",
      "259/259 - 0s - loss: 0.3819 - accuracy: 0.8291 - val_loss: 0.4268 - val_accuracy: 0.8246 - 374ms/epoch - 1ms/step\n",
      "Epoch 64/100\n",
      "259/259 - 0s - loss: 0.3819 - accuracy: 0.8262 - val_loss: 0.4263 - val_accuracy: 0.8174 - 370ms/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "259/259 - 0s - loss: 0.3819 - accuracy: 0.8265 - val_loss: 0.4283 - val_accuracy: 0.8174 - 370ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      "259/259 - 0s - loss: 0.3824 - accuracy: 0.8259 - val_loss: 0.4260 - val_accuracy: 0.8188 - 390ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "259/259 - 0s - loss: 0.3797 - accuracy: 0.8256 - val_loss: 0.4279 - val_accuracy: 0.8213 - 357ms/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "259/259 - 0s - loss: 0.3795 - accuracy: 0.8294 - val_loss: 0.4258 - val_accuracy: 0.8174 - 341ms/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "259/259 - 0s - loss: 0.3785 - accuracy: 0.8281 - val_loss: 0.4246 - val_accuracy: 0.8150 - 365ms/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "259/259 - 0s - loss: 0.3786 - accuracy: 0.8297 - val_loss: 0.4293 - val_accuracy: 0.8101 - 364ms/epoch - 1ms/step\n",
      "Epoch 71/100\n",
      "259/259 - 0s - loss: 0.3784 - accuracy: 0.8279 - val_loss: 0.4306 - val_accuracy: 0.8111 - 353ms/epoch - 1ms/step\n",
      "Epoch 72/100\n",
      "259/259 - 0s - loss: 0.3780 - accuracy: 0.8289 - val_loss: 0.4263 - val_accuracy: 0.8179 - 349ms/epoch - 1ms/step\n",
      "Epoch 73/100\n",
      "259/259 - 0s - loss: 0.3779 - accuracy: 0.8280 - val_loss: 0.4292 - val_accuracy: 0.8198 - 360ms/epoch - 1ms/step\n",
      "Epoch 74/100\n",
      "259/259 - 0s - loss: 0.3774 - accuracy: 0.8281 - val_loss: 0.4289 - val_accuracy: 0.8159 - 350ms/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "259/259 - 0s - loss: 0.3770 - accuracy: 0.8287 - val_loss: 0.4280 - val_accuracy: 0.8213 - 360ms/epoch - 1ms/step\n",
      "Epoch 76/100\n",
      "259/259 - 0s - loss: 0.3750 - accuracy: 0.8327 - val_loss: 0.4347 - val_accuracy: 0.8043 - 378ms/epoch - 1ms/step\n",
      "Epoch 77/100\n",
      "259/259 - 0s - loss: 0.3765 - accuracy: 0.8310 - val_loss: 0.4293 - val_accuracy: 0.8188 - 343ms/epoch - 1ms/step\n",
      "Epoch 78/100\n",
      "259/259 - 0s - loss: 0.3745 - accuracy: 0.8318 - val_loss: 0.4309 - val_accuracy: 0.8121 - 342ms/epoch - 1ms/step\n",
      "Epoch 79/100\n",
      "259/259 - 0s - loss: 0.3749 - accuracy: 0.8320 - val_loss: 0.4284 - val_accuracy: 0.8159 - 350ms/epoch - 1ms/step\n",
      "Epoch 80/100\n",
      "259/259 - 0s - loss: 0.3749 - accuracy: 0.8320 - val_loss: 0.4274 - val_accuracy: 0.8174 - 350ms/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "259/259 - 0s - loss: 0.3733 - accuracy: 0.8320 - val_loss: 0.4295 - val_accuracy: 0.8164 - 343ms/epoch - 1ms/step\n",
      "Epoch 82/100\n",
      "259/259 - 0s - loss: 0.3724 - accuracy: 0.8331 - val_loss: 0.4291 - val_accuracy: 0.8145 - 369ms/epoch - 1ms/step\n",
      "Epoch 83/100\n",
      "259/259 - 0s - loss: 0.3724 - accuracy: 0.8306 - val_loss: 0.4302 - val_accuracy: 0.8130 - 360ms/epoch - 1ms/step\n",
      "Epoch 84/100\n",
      "259/259 - 0s - loss: 0.3736 - accuracy: 0.8317 - val_loss: 0.4371 - val_accuracy: 0.8135 - 349ms/epoch - 1ms/step\n",
      "Epoch 85/100\n",
      "259/259 - 0s - loss: 0.3734 - accuracy: 0.8332 - val_loss: 0.4309 - val_accuracy: 0.8111 - 339ms/epoch - 1ms/step\n",
      "Epoch 86/100\n",
      "259/259 - 0s - loss: 0.3720 - accuracy: 0.8318 - val_loss: 0.4391 - val_accuracy: 0.8024 - 352ms/epoch - 1ms/step\n",
      "Epoch 87/100\n",
      "259/259 - 0s - loss: 0.3725 - accuracy: 0.8294 - val_loss: 0.4287 - val_accuracy: 0.8179 - 351ms/epoch - 1ms/step\n",
      "Epoch 88/100\n",
      "259/259 - 0s - loss: 0.3701 - accuracy: 0.8339 - val_loss: 0.4334 - val_accuracy: 0.8169 - 350ms/epoch - 1ms/step\n",
      "Epoch 89/100\n",
      "259/259 - 0s - loss: 0.3722 - accuracy: 0.8310 - val_loss: 0.4292 - val_accuracy: 0.8164 - 358ms/epoch - 1ms/step\n",
      "Epoch 90/100\n",
      "259/259 - 0s - loss: 0.3697 - accuracy: 0.8332 - val_loss: 0.4341 - val_accuracy: 0.8072 - 344ms/epoch - 1ms/step\n",
      "Epoch 91/100\n",
      "259/259 - 0s - loss: 0.3694 - accuracy: 0.8339 - val_loss: 0.4309 - val_accuracy: 0.8159 - 349ms/epoch - 1ms/step\n",
      "Epoch 92/100\n",
      "259/259 - 0s - loss: 0.3678 - accuracy: 0.8341 - val_loss: 0.4345 - val_accuracy: 0.8116 - 365ms/epoch - 1ms/step\n",
      "Epoch 93/100\n",
      "259/259 - 0s - loss: 0.3692 - accuracy: 0.8346 - val_loss: 0.4301 - val_accuracy: 0.8232 - 367ms/epoch - 1ms/step\n",
      "Epoch 94/100\n",
      "259/259 - 0s - loss: 0.3691 - accuracy: 0.8341 - val_loss: 0.4332 - val_accuracy: 0.8116 - 350ms/epoch - 1ms/step\n",
      "Epoch 95/100\n",
      "259/259 - 0s - loss: 0.3685 - accuracy: 0.8340 - val_loss: 0.4293 - val_accuracy: 0.8184 - 358ms/epoch - 1ms/step\n",
      "Epoch 96/100\n",
      "259/259 - 0s - loss: 0.3693 - accuracy: 0.8355 - val_loss: 0.4344 - val_accuracy: 0.8121 - 359ms/epoch - 1ms/step\n",
      "Epoch 97/100\n",
      "259/259 - 0s - loss: 0.3675 - accuracy: 0.8362 - val_loss: 0.4324 - val_accuracy: 0.8188 - 349ms/epoch - 1ms/step\n",
      "Epoch 98/100\n",
      "259/259 - 0s - loss: 0.3681 - accuracy: 0.8379 - val_loss: 0.4333 - val_accuracy: 0.8159 - 344ms/epoch - 1ms/step\n",
      "Epoch 99/100\n",
      "259/259 - 0s - loss: 0.3668 - accuracy: 0.8345 - val_loss: 0.4314 - val_accuracy: 0.8135 - 454ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "259/259 - 1s - loss: 0.3666 - accuracy: 0.8344 - val_loss: 0.4357 - val_accuracy: 0.8198 - 517ms/epoch - 2ms/step\n",
      "65/65 [==============================] - 0s 1ms/step\n",
      "[0 1 1 ... 0 1 0]\n",
      "Accuracy: 0.8198067632850241\n",
      "Precision: 0.8101898101898102\n",
      "Recall: 0.8158953722334004\n",
      "f1-score: 0.8130325814536341\n",
      "rmse: 0.4244917392776635\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(22, input_dim=24, activation='relu'))\n",
    "model.add(Dense(14, activation='relu'))\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history=model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=100,\n",
    "          verbose=2,\n",
    "          validation_data=(X_test, y_test)) \n",
    "                \n",
    "y_pred = model.predict(X_test)\n",
    "pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(pred)\n",
    "\n",
    "a=accuracy_score(pred, y_test)\n",
    "\n",
    "precision=precision_score(pred,y_test)\n",
    "recall=recall_score(pred,y_test)\n",
    "f1=(2*(precision*recall))/(precision+recall)\n",
    "rmse=math.sqrt(mean_squared_error(y_test,pred))\n",
    "#Printthe accuracy, precision, recall, and F1 score of the result\n",
    "\n",
    "print(\"Accuracy:\",a)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"Recall:\",recall)\n",
    "print(\"f1-score:\", f1)\n",
    "print(\"rmse:\", rmse)\n",
    "\n",
    "#Plot the loss curve\n",
    "plt.plot(history.history['loss']) \n",
    "plt.plot(history.history['val_loss']) \n",
    "plt.title('Model loss') \n",
    "plt.ylabel('Loss') \n",
    "plt.xlabel('Epoch') \n",
    "plt.legend(['Train', 'Test'], loc='upper left') \n",
    "plt.show()\n",
    "\n",
    "#Plot the accurcy curve\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7f9f71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
